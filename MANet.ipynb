{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "tf=T.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':16,\n",
    "        'epochs':500,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='../../data/external/ori/*.png'\n",
    "mask1_path='../../data/external/mask/class1/*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = Image.open(self.img_path[idx])\n",
    "        image_path=tf(image_path)\n",
    "        file_path=os.path.basename(self.img_path[idx])\n",
    "        label1 = np.array(Image.open(self.label[idx]))\n",
    "        label1=label1[:,:,0,np.newaxis]\n",
    "        label2=np.array(Image.open(self.label[idx].replace('/class1', '/class2')))\n",
    "        label2=label2[:,:,0,np.newaxis]\n",
    "        label3=np.array(Image.open(self.label[idx].replace('/class1', '/class3')))\n",
    "        label3=label3[:,:,0,np.newaxis]\n",
    "\n",
    "        label=np.concatenate((label1,label2,label3),axis=2)\n",
    "        label_path = tf(cv2.resize(label, (512, 512)))\n",
    "       \n",
    "        return image_path, label_path,file_path\n",
    "\n",
    "test_dataset = CustomDataset(glob(image_path), glob(mask1_path))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=params['batch_size'],shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, num_classes=3):\n",
    "    smooth = 0\n",
    "    dice_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        A_sum = torch.sum(pred_class * pred_class)\n",
    "        B_sum = torch.sum(target_class * target_class)\n",
    "\n",
    "        dice_per_class[class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return dice_per_class\n",
    "\n",
    "def compute_iou(pred_mask, true_mask, threshold=0.5, num_classes=3):\n",
    "    \"\"\"\n",
    "    IoU를 계산하는 함수\n",
    "\n",
    "    :param pred_mask: 모델이 예측한 마스크 (torch.Tensor)\n",
    "    :param true_mask: 실제 마스크 (torch.Tensor)\n",
    "    :param threshold: 이진화를 위한 임계값\n",
    "    :return: IoU 값\n",
    "    \"\"\"\n",
    "    iou_per_class = torch.zeros(num_classes).to(device)\n",
    "    for class_id in range(num_classes):\n",
    "    # 예측된 마스크 이진화\n",
    "        pred_mask1 = (pred_mask[:,class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 실제 마스크 이진화\n",
    "        true_mask1 = (true_mask[:,class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 교차 계산\n",
    "        intersection = torch.sum(pred_mask1 * true_mask1)\n",
    "        \n",
    "        # 합집합 계산\n",
    "        union = torch.sum(pred_mask1) + torch.sum(true_mask1) - intersection\n",
    "        \n",
    "        # IoU 계산\n",
    "        iou_per_class[class_id]= intersection / union\n",
    "    \n",
    "    return iou_per_class\n",
    "\n",
    "def compute_f1(pred_mask, true_mask, threshold=0.5, num_classes=3):\n",
    "    \"\"\"\n",
    "    F1 점수를 계산하는 함수\n",
    "\n",
    "    :param pred_mask: 모델이 예측한 마스크 (torch.Tensor)\n",
    "    :param true_mask: 실제 마스크 (torch.Tensor)\n",
    "    :param threshold: 이진화를 위한 임계값\n",
    "    :param num_classes: 클래스의 수\n",
    "    :param device: 연산에 사용할 디바이스 (기본값: 'cpu')\n",
    "    :return: 각 클래스별 F1 점수 (torch.Tensor)\n",
    "    \"\"\"\n",
    "    f1_per_class = torch.zeros(num_classes).to(device)\n",
    "    precision1=torch.zeros(num_classes).to(device)\n",
    "    recall1=torch.zeros(num_classes).to(device)\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        # 예측된 마스크 이진화\n",
    "        pred_binary_mask = (pred_mask[:, class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 실제 마스크 이진화\n",
    "        true_binary_mask = (true_mask[:, class_id, ...] > threshold).float()\n",
    "        \n",
    "        # True Positive (TP), False Positive (FP), False Negative (FN) 계산\n",
    "        TP = torch.sum(pred_binary_mask * true_binary_mask)\n",
    "        FP = torch.sum(pred_binary_mask * (1 - true_binary_mask))\n",
    "        FN = torch.sum((1 - pred_binary_mask) * true_binary_mask)\n",
    "        \n",
    "        # 정밀도 (Precision) 계산\n",
    "        precision = TP / (TP + FP + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        \n",
    "        # 재현율 (Recall) 계산\n",
    "        recall = TP / (TP + FN + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        \n",
    "        # F1 점수 계산\n",
    "        f1_per_class[class_id] = 2 * (precision * recall) / (precision + recall + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        precision1[class_id]=precision.item()\n",
    "        recall1[class_id]=recall.item()\n",
    "    \n",
    "    return f1_per_class,precision,recall\n",
    "\n",
    "class MultiClassIoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(MultiClassIoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets,num_classes=3, smooth=1):\n",
    "        num_classes = inputs.shape[1]  # assuming inputs have shape (batch_size, num_classes, height, width)\n",
    "        inputs = F.softmax(inputs, dim=1)  # apply softmax to the input tensor\n",
    "        IOU_per_class = torch.zeros(num_classes).to(device)\n",
    "        for cls in range(num_classes):\n",
    "            input_cls = inputs[:, cls, :, :].contiguous().view(-1)  # flatten the inputs for the current class\n",
    "            target_cls = targets[:, cls, :, :].float().contiguous().view(-1)  # create binary target for the current class\n",
    "\n",
    "            intersection = (input_cls * target_cls).sum()\n",
    "            total = (input_cls + target_cls).sum()\n",
    "            union = total - intersection\n",
    "\n",
    "            IoU = (intersection + smooth) / (union + smooth)\n",
    "            IOU_per_class[cls] = (1 - IoU)\n",
    "\n",
    "        return IOU_per_class # average over all classes\n",
    "    \n",
    "model = smp.MAnet(\n",
    "    encoder_name=\"efficientnet-b5\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ").to(device)\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "criterion = MultiClassIoULoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    model.load_state_dict(torch.load('../../model/MANet/MANet_'+str(i+1)+'_check.pth',map_location=device))\n",
    "    df=pd.DataFrame(columns=['file_name','Dice1','Dice2','Dice3','mDice','IoU1','IoU2','IoU3','mIoU','f1','precision','recall'])\n",
    "    with torch.no_grad():\n",
    "        test = tqdm(test_dataloader)\n",
    "        count = 0\n",
    "        val_running_loss = 0.0\n",
    "        acc_loss = 0\n",
    "        for x, y,file_path in test:\n",
    "            model.eval()\n",
    "            y = y.to(device).float()\n",
    "            count += 1\n",
    "            x = x.to(device).float()\n",
    "            predict = model(x).to(device)\n",
    "            cost = 1-compute_iou(y,predict)  # cost 구함\n",
    "            iou=compute_iou(predict, y)\n",
    "            f1,precision,recall=compute_f1(predict, y)\n",
    "            val_running_loss+=cost.mean().item()\n",
    "            df.loc[len(df)]=[file_path[0],cost[0].item(),cost[1].item(),cost[2].item(),cost.mean().item(),iou[0].item(),iou[1].item(),iou[2].item(),iou.mean().item(),f1.mean().item(),precision.mean().item(),recall.mean().item()]\n",
    "            \n",
    "            test.set_description(\n",
    "                f\"val_Step: {count+1} dice_loss : {val_running_loss/count:.4f}\")\n",
    "    df.to_csv('../../data/external/result/MANet/MANet_'+str(i+1)+'_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/300 Step: 15 iou_loss : 0.9388 iou_score: 0.0612:   5%|▌         | 14/256 [00:19<05:40,  1.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     19\u001b[0m acc_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y,a \u001b[38;5;129;01min\u001b[39;00m test:\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     22\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m image_path\u001b[38;5;241m=\u001b[39mtf(image_path)\n\u001b[1;32m     12\u001b[0m file_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path[idx])\n\u001b[0;32m---> 13\u001b[0m label1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m label1\u001b[38;5;241m=\u001b[39mlabel1[:,:,\u001b[38;5;241m0\u001b[39m,np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m     15\u001b[0m label2\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel[idx]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/class1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/class2\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/Image.py:696\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    694\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/Image.py:755\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    753\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 755\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.9/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "tf=T.ToTensor()\n",
    "params={'image_size':512,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':32,\n",
    "        'epochs':100,}\n",
    "image1=np.load('../../data/cv0_ori.npy')\n",
    "image1=image1.astype(np.uint8)\n",
    "image2=np.load('../../data/cv1_ori.npy')\n",
    "image2=image2.astype(np.uint8)\n",
    "image3=np.load('../../data/cv2_ori.npy')\n",
    "image3=image3.astype(np.uint8)\n",
    "image4=np.load('../../data/cv3_ori.npy')\n",
    "image4=image4.astype(np.uint8)\n",
    "image5=np.load('../../data/cv4_ori.npy')\n",
    "image5=image5.astype(np.uint8)\n",
    "mask1=np.load('../../data/cv0_mask.npy')\n",
    "mask1=(mask1[:,:,:,:3]).astype(np.uint8)\n",
    "mask2=np.load('../../data/cv1_mask.npy')\n",
    "mask2=(mask2[:,:,:,:3]).astype(np.uint8)\n",
    "mask3=np.load('../../data/cv2_mask.npy')\n",
    "mask3=(mask3[:,:,:,:3]).astype(np.uint8)\n",
    "mask4=np.load('../../data/cv3_mask.npy')\n",
    "mask4=(mask4[:,:,:,:3]).astype(np.uint8)\n",
    "mask5=np.load('../../data/cv4_mask.npy')\n",
    "mask5=(mask5[:,:,:,:3]).astype(np.uint8)\n",
    "\n",
    "np_data={'image1':image1,'image2':image2,'image3':image3,'image4':image4,'image5':image5,'mask1':mask1,'mask2':mask2,'mask3':mask3,'mask4':mask4,'mask5':mask5}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.img_path[idx]\n",
    "        image_path=tf(cv2.cvtColor(image_path, cv2.COLOR_GRAY2RGB))\n",
    "        \n",
    "        label_path = self.label[idx]\n",
    "        label_path = tf(cv2.resize(label_path[:,:,:3], (512, 512)))\n",
    "       \n",
    "        return image_path, label_path\n",
    "    \n",
    "def dice_loss(pred, target, num_classes=3):\n",
    "    smooth = 1.\n",
    "    dice_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        A_sum = torch.sum(pred_class * pred_class)\n",
    "        B_sum = torch.sum(target_class * target_class)\n",
    "\n",
    "        dice_per_class[class_id] = 1 - \\\n",
    "            (2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return torch.mean(dice_per_class)\n",
    "def iou_loss(pred, target, num_classes=3):\n",
    "    smooth = 1e-6\n",
    "    iou_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        union = torch.sum(pred_class) + torch.sum(target_class) - intersection\n",
    "\n",
    "        iou_per_class[class_id] = 1 - (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return torch.mean(iou_per_class)\n",
    "    \n",
    "metrics = defaultdict(float)\n",
    "for k in range(2,5):\n",
    "    val_loss=1000\n",
    "    df=pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss', 'train_acc', 'val_acc'])\n",
    "    train_list=[0,1,2,3,4]\n",
    "    train_list.remove(k)\n",
    "    train_image=np.concatenate([np_data['image'+str(i+1)] for i in train_list])\n",
    "    train_mask=np.concatenate([np_data['mask'+str(i+1)] for i in train_list])\n",
    "    val_image=np_data['image'+str(k+1)]\n",
    "    val_mask=np_data['mask'+str(k+1)]\n",
    "    train_dataset = CustomDataset(train_image, train_mask)\n",
    "\n",
    "    val_dataset = CustomDataset(val_image, val_mask)\n",
    "    train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n",
    "    validation_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n",
    "    ealry_count=0\n",
    "    model = smp.MAnet(\n",
    "        encoder_name=\"efficientnet-b5\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=3,                      # model output channels (number of classes in your dataset) \n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "    for epoch in range(100):\n",
    "        train = tqdm(train_dataloader)\n",
    "        count = 0\n",
    "        running_loss = 0.0\n",
    "        acc_loss = 0\n",
    "        for x, y in train:\n",
    "            model.train()\n",
    "            y = y.to(device).float()\n",
    "            count += 1\n",
    "            x = x.to(device).float()\n",
    "            optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "            predict = model(x).to(device)\n",
    "            cost = iou_loss(predict, y)  # cost 구함\n",
    "            acc = 1-cost.item()\n",
    "            cost.backward()  # cost에 대한 backward 구함\n",
    "            optimizer.step()\n",
    "            running_loss += cost.item()\n",
    "            acc_loss += acc\n",
    "            train.set_description(\n",
    "                f\"epoch: {epoch+1}/{300} Step: {count+1} iou_loss : {running_loss/count:.4f} iou_score: {1-running_loss/count:.4f}\")\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            val = tqdm(validation_dataloader)\n",
    "            count = 0\n",
    "            val_running_loss = 0.0\n",
    "            acc_loss = 0\n",
    "            for x, y in val:\n",
    "                model.eval()\n",
    "                y = y.to(device).float()\n",
    "                count += 1\n",
    "                x = x.to(device).float()\n",
    "                predict = model(x).to(device)\n",
    "                cost= iou_loss(predict, y)  # cost 구함\n",
    "                acc = 1-cost.item()\n",
    "                val_running_loss += cost.item()\n",
    "                acc_loss += acc\n",
    "                val.set_description(\n",
    "                    f\"val_epoch: {epoch+1}/{300} Step: {count+1} iou_loss : {val_running_loss/count:.4f} iou_score: {1-val_running_loss/count:.4f}\")\n",
    "        if val_loss>(val_running_loss/count):\n",
    "            ealry_count=0\n",
    "            val_loss=val_running_loss/count\n",
    "            torch.save(model.state_dict(), '../../model/MANet/MANet_'+str(k+1)+'_check.pth')\n",
    "        else:\n",
    "            ealry_count+=1\n",
    "            if epoch>10 and ealry_count==3:\n",
    "                break\n",
    "        df.loc[len(df)]=[epoch+1,running_loss/len(train_dataloader),val_running_loss/len(validation_dataloader),1-running_loss/len(train_dataloader),1-val_running_loss/len(validation_dataloader)]\n",
    "        df.to_csv('../../model/MANet/MANet_'+str(k+1)+'.csv',index=False)\n",
    "    torch.save(model.state_dict(), '../../model/MANet/MANet_'+str(k+1)+'.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0226,  0.0031, -0.0097], device='cuda:5', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
