{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "tf=T.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':16,\n",
    "        'epochs':500,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='../../data/external/ori/*.png'\n",
    "mask1_path='../../data/external/mask/class1/*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = Image.open(self.img_path[idx])\n",
    "        image_path=tf(image_path)\n",
    "        file_path=os.path.basename(self.img_path[idx])\n",
    "        label1 = np.array(Image.open(self.label[idx]))\n",
    "        label1=label1[:,:,0,np.newaxis]\n",
    "        label2=np.array(Image.open(self.label[idx].replace('/class1', '/class2')))\n",
    "        label2=label2[:,:,0,np.newaxis]\n",
    "        label3=np.array(Image.open(self.label[idx].replace('/class1', '/class3')))\n",
    "        label3=label3[:,:,0,np.newaxis]\n",
    "\n",
    "        label=np.concatenate((label1,label2,label3),axis=2)\n",
    "        label_path = tf(cv2.resize(label, (512, 512)))\n",
    "       \n",
    "        return image_path, label_path,file_path\n",
    "\n",
    "test_dataset = CustomDataset(glob(image_path), glob(mask1_path))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=params['batch_size'],shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, num_classes=3):\n",
    "    smooth = 0\n",
    "    dice_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        A_sum = torch.sum(pred_class * pred_class)\n",
    "        B_sum = torch.sum(target_class * target_class)\n",
    "\n",
    "        dice_per_class[class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return dice_per_class\n",
    "\n",
    "def compute_iou(pred_mask, true_mask, threshold=0.5, num_classes=3):\n",
    "    \"\"\"\n",
    "    IoU를 계산하는 함수\n",
    "\n",
    "    :param pred_mask: 모델이 예측한 마스크 (torch.Tensor)\n",
    "    :param true_mask: 실제 마스크 (torch.Tensor)\n",
    "    :param threshold: 이진화를 위한 임계값\n",
    "    :return: IoU 값\n",
    "    \"\"\"\n",
    "    iou_per_class = torch.zeros(num_classes).to(device)\n",
    "    for class_id in range(num_classes):\n",
    "    # 예측된 마스크 이진화\n",
    "        pred_mask1 = (pred_mask[:,class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 실제 마스크 이진화\n",
    "        true_mask1 = (true_mask[:,class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 교차 계산\n",
    "        intersection = torch.sum(pred_mask1 * true_mask1)\n",
    "        \n",
    "        # 합집합 계산\n",
    "        union = torch.sum(pred_mask1) + torch.sum(true_mask1) - intersection\n",
    "        \n",
    "        # IoU 계산\n",
    "        iou_per_class[class_id]= intersection / union\n",
    "    \n",
    "    return iou_per_class\n",
    "\n",
    "def compute_f1(pred_mask, true_mask, threshold=0.5, num_classes=3):\n",
    "    \"\"\"\n",
    "    F1 점수를 계산하는 함수\n",
    "\n",
    "    :param pred_mask: 모델이 예측한 마스크 (torch.Tensor)\n",
    "    :param true_mask: 실제 마스크 (torch.Tensor)\n",
    "    :param threshold: 이진화를 위한 임계값\n",
    "    :param num_classes: 클래스의 수\n",
    "    :param device: 연산에 사용할 디바이스 (기본값: 'cpu')\n",
    "    :return: 각 클래스별 F1 점수 (torch.Tensor)\n",
    "    \"\"\"\n",
    "    f1_per_class = torch.zeros(num_classes).to(device)\n",
    "    precision1=torch.zeros(num_classes).to(device)\n",
    "    recall1=torch.zeros(num_classes).to(device)\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        # 예측된 마스크 이진화\n",
    "        pred_binary_mask = (pred_mask[:, class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 실제 마스크 이진화\n",
    "        true_binary_mask = (true_mask[:, class_id, ...] > threshold).float()\n",
    "        \n",
    "        # True Positive (TP), False Positive (FP), False Negative (FN) 계산\n",
    "        TP = torch.sum(pred_binary_mask * true_binary_mask)\n",
    "        FP = torch.sum(pred_binary_mask * (1 - true_binary_mask))\n",
    "        FN = torch.sum((1 - pred_binary_mask) * true_binary_mask)\n",
    "        \n",
    "        # 정밀도 (Precision) 계산\n",
    "        precision = TP / (TP + FP + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        \n",
    "        # 재현율 (Recall) 계산\n",
    "        recall = TP / (TP + FN + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        \n",
    "        # F1 점수 계산\n",
    "        f1_per_class[class_id] = 2 * (precision * recall) / (precision + recall + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        precision1[class_id]=precision.item()\n",
    "        recall1[class_id]=recall.item()\n",
    "    \n",
    "    return f1_per_class,precision,recall\n",
    "\n",
    "class MultiClassIoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(MultiClassIoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets,num_classes=3, smooth=1):\n",
    "        num_classes = inputs.shape[1]  # assuming inputs have shape (batch_size, num_classes, height, width)\n",
    "        inputs = F.softmax(inputs, dim=1)  # apply softmax to the input tensor\n",
    "        IOU_per_class = torch.zeros(num_classes).to(device)\n",
    "        for cls in range(num_classes):\n",
    "            input_cls = inputs[:, cls, :, :].contiguous().view(-1)  # flatten the inputs for the current class\n",
    "            target_cls = targets[:, cls, :, :].float().contiguous().view(-1)  # create binary target for the current class\n",
    "\n",
    "            intersection = (input_cls * target_cls).sum()\n",
    "            total = (input_cls + target_cls).sum()\n",
    "            union = total - intersection\n",
    "\n",
    "            IoU = (intersection + smooth) / (union + smooth)\n",
    "            IOU_per_class[cls] = (1 - IoU)\n",
    "\n",
    "        return IOU_per_class # average over all classes\n",
    "    \n",
    "model = smp.MAnet(\n",
    "    encoder_name=\"efficientnet-b5\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ").to(device)\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "criterion = MultiClassIoULoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_Step: 3 dice_loss : 1.0846:   1%|          | 2/256 [00:04<09:54,  2.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m val_running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     10\u001b[0m acc_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y,file_path \u001b[38;5;129;01min\u001b[39;00m test:\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m image_path\u001b[38;5;241m=\u001b[39mtf(image_path)\n\u001b[1;32m     12\u001b[0m file_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path[idx])\n\u001b[0;32m---> 13\u001b[0m label1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m label1\u001b[38;5;241m=\u001b[39mlabel1[:,:,\u001b[38;5;241m0\u001b[39m,np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m     15\u001b[0m label2\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel[idx]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/class1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/class2\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m~/anaconda3/envs/LeeYS/lib/python3.10/site-packages/PIL/Image.py:3131\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3128\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3131\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3132\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    \n",
    "    model.load_state_dict(torch.load('../../model/MANet/MANet_'+str(i+1)+'_check.pth',map_location=device))\n",
    "    model.to(device)\n",
    "    df=pd.DataFrame(columns=['file_name','Dice1','Dice2','Dice3','mDice','IoU1','IoU2','IoU3','mIoU','f1','precision','recall'])\n",
    "    with torch.no_grad():\n",
    "        test = tqdm(test_dataloader)\n",
    "        count = 0\n",
    "        val_running_loss = 0.0\n",
    "        acc_loss = 0\n",
    "        for x, y,file_path in test:\n",
    "            model.eval()\n",
    "            y = y.to(device).float()\n",
    "            count += 1\n",
    "            x = x.to(device).float()\n",
    "            predict = model(x).to(device)\n",
    "            cost = 1-dice_loss(y,predict)  # cost 구함\n",
    "            iou=dice_loss(predict, y)\n",
    "            f1,precision,recall=compute_f1(predict, y)\n",
    "            val_running_loss+=cost.mean().item()\n",
    "            df.loc[len(df)]=[file_path[0],cost[0].item(),cost[1].item(),cost[2].item(),cost.mean().item(),iou[0].item(),iou[1].item(),iou[2].item(),iou.mean().item(),f1.mean().item(),precision.mean().item(),recall.mean().item()]\n",
    "            \n",
    "            test.set_description(\n",
    "                f\"val_Step: {count+1} dice_loss : {val_running_loss/count:.4f}\")\n",
    "    df.to_csv('../../data/external/result/MANet/MANet_'+str(i+1)+'_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
