{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "tf=T.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'image_size':512,\n",
    "        'lr':2e-3,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':1,\n",
    "        'epochs':500,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='../../data/external/ori/*.png'\n",
    "mask1_path='../../data/external/mask/class1/*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = Image.open(self.img_path[idx])\n",
    "        image_path=tf(image_path)\n",
    "        file_path=os.path.basename(self.img_path[idx])\n",
    "        label1 = np.array(Image.open(self.label[idx]))\n",
    "        label1=label1[:,:,0,np.newaxis]\n",
    "        label2=np.array(Image.open(self.label[idx].replace('/class1', '/class2')))\n",
    "        label2=label2[:,:,0,np.newaxis]\n",
    "        label3=np.array(Image.open(self.label[idx].replace('/class1', '/class3')))\n",
    "        label3=label3[:,:,0,np.newaxis]\n",
    "\n",
    "        label=np.concatenate((label1,label2,label3),axis=2)\n",
    "        label_path = tf(cv2.resize(label, (512, 512)))\n",
    "       \n",
    "        return image_path, label_path,file_path\n",
    "\n",
    "test_dataset = CustomDataset(glob(image_path), glob(mask1_path))\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=params['batch_size'],shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, num_classes=3):\n",
    "    smooth = 0\n",
    "    dice_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        A_sum = torch.sum(pred_class * pred_class)\n",
    "        B_sum = torch.sum(target_class * target_class)\n",
    "\n",
    "        dice_per_class[class_id] =(2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return dice_per_class\n",
    "\n",
    "def compute_iou(pred_mask, true_mask, threshold=0.5, num_classes=3):\n",
    "    \"\"\"\n",
    "    IoU를 계산하는 함수\n",
    "\n",
    "    :param pred_mask: 모델이 예측한 마스크 (torch.Tensor)\n",
    "    :param true_mask: 실제 마스크 (torch.Tensor)\n",
    "    :param threshold: 이진화를 위한 임계값\n",
    "    :return: IoU 값\n",
    "    \"\"\"\n",
    "    iou_per_class = torch.zeros(num_classes).to(device)\n",
    "    for class_id in range(num_classes):\n",
    "    # 예측된 마스크 이진화\n",
    "        pred_mask1 = (pred_mask[:,class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 실제 마스크 이진화\n",
    "        true_mask1 = (true_mask[:,class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 교차 계산\n",
    "        intersection = torch.sum(pred_mask1 * true_mask1)\n",
    "        \n",
    "        # 합집합 계산\n",
    "        union = torch.sum(pred_mask1) + torch.sum(true_mask1) - intersection\n",
    "        \n",
    "        # IoU 계산\n",
    "        iou_per_class[class_id]= intersection / union\n",
    "    \n",
    "    return iou_per_class\n",
    "\n",
    "def compute_f1(pred_mask, true_mask, threshold=0.5, num_classes=3):\n",
    "    \"\"\"\n",
    "    F1 점수를 계산하는 함수\n",
    "\n",
    "    :param pred_mask: 모델이 예측한 마스크 (torch.Tensor)\n",
    "    :param true_mask: 실제 마스크 (torch.Tensor)\n",
    "    :param threshold: 이진화를 위한 임계값\n",
    "    :param num_classes: 클래스의 수\n",
    "    :param device: 연산에 사용할 디바이스 (기본값: 'cpu')\n",
    "    :return: 각 클래스별 F1 점수 (torch.Tensor)\n",
    "    \"\"\"\n",
    "    f1_per_class = torch.zeros(num_classes).to(device)\n",
    "    precision1=torch.zeros(num_classes).to(device)\n",
    "    recall1=torch.zeros(num_classes).to(device)\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        # 예측된 마스크 이진화\n",
    "        pred_binary_mask = (pred_mask[:, class_id, ...] > threshold).float()\n",
    "        \n",
    "        # 실제 마스크 이진화\n",
    "        true_binary_mask = (true_mask[:, class_id, ...] > threshold).float()\n",
    "        \n",
    "        # True Positive (TP), False Positive (FP), False Negative (FN) 계산\n",
    "        TP = torch.sum(pred_binary_mask * true_binary_mask)\n",
    "        FP = torch.sum(pred_binary_mask * (1 - true_binary_mask))\n",
    "        FN = torch.sum((1 - pred_binary_mask) * true_binary_mask)\n",
    "        \n",
    "        # 정밀도 (Precision) 계산\n",
    "        precision = TP / (TP + FP + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        \n",
    "        # 재현율 (Recall) 계산\n",
    "        recall = TP / (TP + FN + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        \n",
    "        # F1 점수 계산\n",
    "        f1_per_class[class_id] = 2 * (precision * recall) / (precision + recall + 1e-8)  # 분모가 0이 되는 것을 방지하기 위해 작은 값 추가\n",
    "        precision1[class_id]=precision.item()\n",
    "        recall1[class_id]=recall.item()\n",
    "    \n",
    "    return f1_per_class,precision,recall\n",
    "\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\",num_labels=3,ignore_mismatched_sizes=True).to(device)\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    model.load_state_dict(torch.load('../../model/segformer/seg_former_'+str(i+1)+'.pth',map_location=device))\n",
    "    df=pd.DataFrame(columns=['file_name','Dice1','Dice2','Dice3','mDice','IoU1','IoU2','IoU3','mIoU','f1','precision','recall'])\n",
    "    with torch.no_grad():\n",
    "        test = tqdm(test_dataloader)\n",
    "        count = 0\n",
    "        val_running_loss = 0.0\n",
    "        acc_loss = 0\n",
    "        for x, y,file_path in test:\n",
    "            model.eval()\n",
    "            y = y.to(device).float()\n",
    "            count += 1\n",
    "            x = x.to(device).float()\n",
    "            output =model(x).logits.cpu()\n",
    "            predict = nn.functional.interpolate(\n",
    "                    output,\n",
    "                    size=(512,512),\n",
    "                    mode=\"bilinear\",\n",
    "                    align_corners=False,\n",
    "            ).to(device)\n",
    "            cost = dice_loss(predict, y)  # cost 구함\n",
    "            iou=compute_iou(predict, y)\n",
    "            f1,precision,recall=compute_f1(predict, y)\n",
    "            \n",
    "            df.loc[len(df)]=[file_path[0],cost[0].item(),cost[1].item(),cost[2].item(),cost.mean().item(),iou[0].item(),iou[1].item(),iou[2].item(),iou.mean().item(),f1.mean().item(),precision.mean().item(),recall.mean().item()]\n",
    "            \n",
    "            test.set_description(\n",
    "                f\"val_Step: {count+1}\")\n",
    "    df.to_csv('../../data/external/result/segformer/segformer_'+str(i+1)+'_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerImageProcessor, AutoModelForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "tf=T.ToTensor()\n",
    "params={'image_size':512,\n",
    "        'lr':2e-4,\n",
    "        'beta1':0.5,\n",
    "        'beta2':0.999,\n",
    "        'batch_size':48,\n",
    "        'epochs':100,}\n",
    "image1=np.load('../../data/cv0_ori.npy')\n",
    "image1=image1.astype(np.uint8)\n",
    "image2=np.load('../../data/cv1_ori.npy')\n",
    "image2=image2.astype(np.uint8)\n",
    "image3=np.load('../../data/cv2_ori.npy')\n",
    "image3=image3.astype(np.uint8)\n",
    "image4=np.load('../../data/cv3_ori.npy')\n",
    "image4=image4.astype(np.uint8)\n",
    "image5=np.load('../../data/cv4_ori.npy')\n",
    "image5=image5.astype(np.uint8)\n",
    "mask1=np.load('../../data/cv0_mask.npy')\n",
    "mask1=(mask1[:,:,:,:3]).astype(np.uint8)\n",
    "mask2=np.load('../../data/cv1_mask.npy')\n",
    "mask2=(mask2[:,:,:,:3]).astype(np.uint8)\n",
    "mask3=np.load('../../data/cv2_mask.npy')\n",
    "mask3=(mask3[:,:,:,:3]).astype(np.uint8)\n",
    "mask4=np.load('../../data/cv3_mask.npy')\n",
    "mask4=(mask4[:,:,:,:3]).astype(np.uint8)\n",
    "mask5=np.load('../../data/cv4_mask.npy')\n",
    "mask5=(mask5[:,:,:,:3]).astype(np.uint8)\n",
    "\n",
    "np_data={'image1':image1,'image2':image2,'image3':image3,'image4':image4,'image5':image5,'mask1':mask1,'mask2':mask2,'mask3':mask3,'mask4':mask4,'mask5':mask5}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, label_list):\n",
    "        self.img_path = image_list\n",
    "        self.label = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.img_path[idx]\n",
    "        image_path=tf(cv2.cvtColor(image_path, cv2.COLOR_GRAY2RGB))\n",
    "        \n",
    "        label_path = self.label[idx]\n",
    "        label_path = tf(cv2.resize(label_path, (512, 512)))\n",
    "       \n",
    "        return image_path, label_path\n",
    "    \n",
    "def dice_loss(pred, target, num_classes=3):\n",
    "    smooth = 1.\n",
    "    dice_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        A_sum = torch.sum(pred_class * pred_class)\n",
    "        B_sum = torch.sum(target_class * target_class)\n",
    "\n",
    "        dice_per_class[class_id] = 1 - \\\n",
    "            (2. * intersection + smooth) / (A_sum + B_sum + smooth)\n",
    "\n",
    "    return torch.mean(dice_per_class)\n",
    "\n",
    "def iou_loss(pred, target, num_classes=3):\n",
    "    smooth = 1e-6\n",
    "    iou_per_class = torch.zeros(num_classes).to(pred.device)\n",
    "\n",
    "    for class_id in range(num_classes):\n",
    "        pred_class = pred[:, class_id, ...]\n",
    "        target_class = target[:, class_id, ...]\n",
    "\n",
    "        intersection = torch.sum(pred_class * target_class)\n",
    "        union = torch.sum(pred_class) + torch.sum(target_class) - intersection\n",
    "\n",
    "        iou_per_class[class_id] = 1 - (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return torch.mean(iou_per_class)\n",
    "    \n",
    "metrics = defaultdict(float)\n",
    "for k in range(2,5):\n",
    "    val_loss=1000\n",
    "    df=pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss', 'train_acc', 'val_acc'])\n",
    "    train_list=[0,1,2,3,4]\n",
    "    train_list.remove(k)\n",
    "    train_image=np.concatenate([np_data['image'+str(i+1)] for i in train_list])\n",
    "    train_mask=np.concatenate([np_data['mask'+str(i+1)] for i in train_list])\n",
    "    val_image=np_data['image'+str(k+1)]\n",
    "    val_mask=np_data['mask'+str(k+1)]\n",
    "    train_dataset = CustomDataset(train_image, train_mask)\n",
    "\n",
    "    val_dataset = CustomDataset(val_image, val_mask)\n",
    "    train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n",
    "    validation_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=params['batch_size'], shuffle=True, drop_last=True)\n",
    "    ealry_count=0\n",
    "    model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\",num_labels=3,ignore_mismatched_sizes=True).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=params['lr'], betas=(params['beta1'], params['beta2']))\n",
    "    for epoch in range(300):\n",
    "        train = tqdm(train_dataloader)\n",
    "        count = 0\n",
    "        running_loss = 0.0\n",
    "        acc_loss = 0\n",
    "        \n",
    "        for x, y in train:\n",
    "            model.train()\n",
    "            y = y.to(device).float()\n",
    "            count += 1\n",
    "            x = x.to(device).float()\n",
    "            optimizer.zero_grad()  # optimizer zero 로 초기화\n",
    "            predict = model(x).logits.to(device)\n",
    "            predict = nn.functional.interpolate(\n",
    "                predict,\n",
    "                size=(512,512),\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False,\n",
    "            )\n",
    "            cost = iou_loss(predict, y)  # cost 구함\n",
    "            acc = 1-cost.item()\n",
    "            cost.backward()  # cost에 대한 backward 구함\n",
    "            optimizer.step()\n",
    "            running_loss += cost.item()\n",
    "            acc_loss += acc\n",
    "            train.set_description(\n",
    "                f\"epoch: {epoch+1}/{300} Step: {count+1} iou_loss : {running_loss/count:.4f} iou_score: {1-running_loss/count:.4f}\")\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            val = tqdm(validation_dataloader)\n",
    "            count = 0\n",
    "            val_running_loss = 0.0\n",
    "            acc_loss = 0\n",
    "            for x, y in val:\n",
    "                model.eval()\n",
    "                y = y.to(device).float()\n",
    "                count += 1\n",
    "                x = x.to(device).float()\n",
    "                predict = model(x).logits.to(device)\n",
    "                predict = nn.functional.interpolate(\n",
    "                    predict,\n",
    "                    size=(512,512),\n",
    "                    mode=\"bilinear\",\n",
    "                    align_corners=False,\n",
    "                )\n",
    "                cost = iou_loss(predict, y)  # cost 구함\n",
    "                acc = 1-cost.item()\n",
    "                val_running_loss += cost.item()\n",
    "                acc_loss += acc\n",
    "\n",
    "                val.set_description(\n",
    "                    f\"val_epoch: {epoch+1}/{300} Step: {count+1} iou_loss : {val_running_loss/count:.4f} iou_score: {1-val_running_loss/count:.4f}\")\n",
    "        if val_loss>val_running_loss/count:\n",
    "            ealry_count=0\n",
    "            val_loss=val_running_loss/count\n",
    "            torch.save(model.state_dict(), '../../model/segformer/seg_former_'+str(k+1)+'_check.pth')\n",
    "        else:\n",
    "            ealry_count+=1\n",
    "            if epoch>10 and ealry_count==3:\n",
    "                break\n",
    "        df.loc[len(df)]=[epoch+1,running_loss/len(train_dataloader),val_running_loss/len(validation_dataloader),1-running_loss/len(train_dataloader),1-val_running_loss/len(validation_dataloader)]\n",
    "        df.to_csv('../../model/segformer/seg_former_'+str(k+1)+'.csv',index=False)\n",
    "    torch.save(model.state_dict(), '../../model/segformer/seg_former_'+str(k+1)+'.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeeYS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
